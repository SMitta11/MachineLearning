{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "_cell_guid": "d66580d1-f255-86b9-e5c0-f012342ab8d8",
        "id": "r9V2T0BZdcco",
        "outputId": "5d717434-d21e-4681-95b2-b1010f41a61e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   PassengerId  Survived  Pclass  \\\n",
              "0            1         0       3   \n",
              "1            2         1       1   \n",
              "2            3         1       3   \n",
              "\n",
              "                                                Name     Sex   Age  SibSp  \\\n",
              "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
              "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
              "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
              "\n",
              "   Parch            Ticket     Fare Cabin Embarked  \n",
              "0      0         A/5 21171   7.2500   NaN        S  \n",
              "1      0          PC 17599  71.2833   C85        C  \n",
              "2      0  STON/O2. 3101282   7.9250   NaN        S  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-acfcd499-7d7f-4ae8-a267-aac4a522a7f2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-acfcd499-7d7f-4ae8-a267-aac4a522a7f2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-acfcd499-7d7f-4ae8-a267-aac4a522a7f2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-acfcd499-7d7f-4ae8-a267-aac4a522a7f2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import re\n",
        "\n",
        "\n",
        "from collections import Counter\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from IPython.display import Image as PImage\n",
        "from subprocess import check_call\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount = True)\n",
        "\n",
        "\n",
        "# Loading the data\n",
        "#train = pd.read_csv('../input/train.csv')\n",
        "train = pd.read_csv('/content/drive/MyDrive/data/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/data/test.csv')\n",
        "test_survival = pd.read_csv('/content/drive/MyDrive/data/gender_submission.csv')\n",
        "\n",
        "# test = pd.read_csv('../input/test.csv')\n",
        "\n",
        "# Store our test passenger IDs for easy access\n",
        "PassengerId = test['PassengerId']\n",
        "\n",
        "# Showing overview of the train dataset\n",
        "train.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing the data for Titanic dataset"
      ],
      "metadata": {
        "id": "fpluopo-BOh_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "_cell_guid": "72063fe1-8b92-850b-3ede-5e030c7429ae",
        "id": "AqRdJxj8dccr"
      },
      "outputs": [],
      "source": [
        "# Copy original dataset in case we need it later when digging into interesting features\n",
        "# WARNING: Beware of actually copying the dataframe instead of just referencing it\n",
        "# \"original_train = train\" will create a reference to the train variable (changes in 'train' will apply to 'original_train')\n",
        "original_train = train.copy() # Using 'copy()' allows to clone the dataset, creating a different object with the same values\n",
        "\n",
        "# Feature engineering steps taken from Sina and Anisotropic, with minor changes to avoid warnings\n",
        "full_data = [train, test]\n",
        "\n",
        "# Feature that tells whether a passenger had a cabin on the Titanic\n",
        "train['Has_Cabin'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
        "test['Has_Cabin'] = test[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
        "\n",
        "# Create new feature FamilySize as a combination of SibSp and Parch\n",
        "for dataset in full_data:\n",
        "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
        "# Create new feature IsAlone from FamilySize\n",
        "for dataset in full_data:\n",
        "    dataset['IsAlone'] = 0\n",
        "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n",
        "# Remove all NULLS in the Embarked column\n",
        "for dataset in full_data:\n",
        "    dataset['Embarked'] = dataset['Embarked'].fillna('S')\n",
        "# Remove all NULLS in the Fare column\n",
        "for dataset in full_data:\n",
        "    dataset['Fare'] = dataset['Fare'].fillna(train['Fare'].median())\n",
        "\n",
        "# Remove all NULLS in the Age column\n",
        "for dataset in full_data:\n",
        "    age_avg = dataset['Age'].mean()\n",
        "    age_std = dataset['Age'].std()\n",
        "    age_null_count = dataset['Age'].isnull().sum()\n",
        "    age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\n",
        "    # Next line has been improved to avoid warning\n",
        "    dataset.loc[np.isnan(dataset['Age']), 'Age'] = age_null_random_list\n",
        "    dataset['Age'] = dataset['Age'].astype(int)\n",
        "\n",
        "# Define function to extract titles from passenger names\n",
        "def get_title(name):\n",
        "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
        "    # If the title exists, extract and return it.\n",
        "    if title_search:\n",
        "        return title_search.group(1)\n",
        "    return \"\"\n",
        "\n",
        "for dataset in full_data:\n",
        "    dataset['Title'] = dataset['Name'].apply(get_title)\n",
        "# Group all non-common titles into one single grouping \"Rare\"\n",
        "for dataset in full_data:\n",
        "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
        "\n",
        "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
        "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
        "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
        "\n",
        "for dataset in full_data:\n",
        "    # Mapping Sex\n",
        "    dataset['Sex'] = dataset['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n",
        "    \n",
        "    # Mapping titles\n",
        "    title_mapping = {\"Mr\": 1, \"Master\": 2, \"Mrs\": 3, \"Miss\": 4, \"Rare\": 5}\n",
        "    dataset['Title'] = dataset['Title'].map(title_mapping)\n",
        "    dataset['Title'] = dataset['Title'].fillna(0)\n",
        "\n",
        "    # Mapping Embarked\n",
        "    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
        "    \n",
        "    # Mapping Fare\n",
        "    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] \t\t\t\t\t\t        = 0\n",
        "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
        "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
        "    dataset.loc[ dataset['Fare'] > 31, 'Fare'] \t\t\t\t\t\t\t        = 3\n",
        "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
        "    \n",
        "    # Mapping Age\n",
        "    dataset.loc[ dataset['Age'] <= 16, 'Age'] \t\t\t\t\t       = 0\n",
        "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
        "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
        "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
        "    dataset.loc[ dataset['Age'] > 64, 'Age'] ;"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature selection: remove variables no longer containing relevant information\n",
        "drop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp']\n",
        "train = train.drop(drop_elements, axis = 1)\n",
        "test  = test.drop(drop_elements, axis = 1)"
      ],
      "metadata": {
        "id": "rqTYWN7Q9RRJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "X_train,y_train,X_test,y_test data"
      ],
      "metadata": {
        "id": "6Q8Cdu-WD8M3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train.iloc[:,1:].values #train data all features to predict if passanger survived or not\n",
        "X_train = np.array(X_train)\n",
        "\n",
        "y_train = train.iloc[:,0].values #train data \"survived\"\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "X_test = test.iloc[:100,:].values#test data all features \n",
        "X_test = np.array(X_test)\n",
        "\n",
        "y_test = test_survival.iloc[:100,-1].values#Y test data for \"survived\"\n",
        "y_test = np.array(y_test)\n"
      ],
      "metadata": {
        "id": "xDV6zQOh5o00"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Trees"
      ],
      "metadata": {
        "id": "4UinX1mQBxij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecisionTree:\n",
        "    \n",
        "    def __init__(self, max_depth=10, min_samples_split=5, min_samples_leaf=2,criterion=\"gini\"):\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.min_samples_leaf = min_samples_leaf\n",
        "        self.criterion = criterion\n",
        "        self.criterion_function = None\n",
        "\n",
        "    def fit(self, X, y,sample_weight=None):\n",
        "      self.classes = len(np.unique(y))\n",
        "      self.tree = self.buildTree(X, y)\n",
        "\n",
        "\n",
        "    # Calculate entropy\n",
        "    def entropy(self, y):\n",
        "        frequency_count = np.bincount(y)\n",
        "        normalized_frequency_count = frequency_count / len(y)\n",
        "        entropy = -np.sum([i * np.log2(i) for i in normalized_frequency_count if i > 0])\n",
        "        return entropy\n",
        "    def gini_impurity(self,y):\n",
        "        _, counts = np.unique(y, return_counts=True)\n",
        "        probs = counts / len(y)\n",
        "        impurity = 1 - np.sum(np.square(probs))\n",
        "        return impurity\n",
        "    #Calculate gini\n",
        "    def gini(self, y):\n",
        "      samples = len(y)\n",
        "      gini = 1.0 - sum((np.sum(y == i) / samples) ** 2 for i in range(self.classes))\n",
        "      return gini\n",
        "    \n",
        "\n",
        "    #Calculate missclassification\n",
        "    def missclassification(self, y):\n",
        "        samples = len(y)\n",
        "        missclassification = 1.0 - np.max([np.sum(y == i) / samples for i in range(self.classes)])\n",
        "        return missclassification\n",
        "\n",
        "    def predict(self, X):\n",
        "      y_pred = []\n",
        "      for inputs in X:\n",
        "          output = self.predict_helper(inputs)\n",
        "          #print(output,\"output\")\n",
        "          y_pred.append(output)\n",
        "      return y_pred\n",
        "\n",
        "\n",
        "    def predict_helper(self, inputs):\n",
        "        node = self.tree\n",
        "        while 'predicted_class' not in node:\n",
        "            if inputs[node['splitting_feature']] < node['threshold']:\n",
        "                node = node['left']\n",
        "            else:\n",
        "                node = node['right']\n",
        "        return node['predicted_class']\n",
        "\n",
        "    def calculate_threshold_classes(self,index_b,X,y):\n",
        "      thresholds = []\n",
        "      classes = []\n",
        "      for i in range(len(y)):\n",
        "              min_index = np.argmin(X[:, index_b])\n",
        "              thresholds.append(X[min_index, index_b])\n",
        "              classes.append(y[min_index])\n",
        "              X = np.delete(X, min_index, axis=0)\n",
        "              y = np.delete(y, min_index)\n",
        "      return thresholds,classes\n",
        "\n",
        "    def calculate_th(self,X,y,idx):\n",
        "      return zip(*sorted(zip(X[:, idx], y)))\n",
        "\n",
        "    def bestSplit(self, X, y):\n",
        "      samples = len(y)\n",
        "      if self.criterion == \"entropy\":\n",
        "        criterion_function = self.entropy\n",
        "      if self.criterion == \"gini\":\n",
        "        criterion_function = self.gini\n",
        "      if self.criterion == \"missclassification\":\n",
        "        criterion_function = self.missclassification\n",
        "      best_criterion = criterion_function(y)\n",
        "      best_index = None\n",
        "      best_threshold = None\n",
        "      \n",
        "      for index_b in range(X.shape[1]):\n",
        "          thresholds, classes = self.calculate_th(X,y,index_b)\n",
        "          \n",
        "          num_left = [0] * self.classes #initialize it to 0 \n",
        "          num_right = [np.sum(y == c) for c in range(self.classes)]\n",
        "          for i in range(1, samples):\n",
        "              c = classes[i - 1]\n",
        "              num_left[c] += 1\n",
        "              num_right[c] -= 1\n",
        "              if i < self.min_samples_leaf or samples - i < self.min_samples_leaf:\n",
        "                  continue\n",
        "              criterion_left = criterion_function(num_left)\n",
        "              criterion_right = criterion_function(num_right)\n",
        "              criterion = (i * criterion_left + (samples - i) * criterion_right) / samples\n",
        "              #print(\"criterion1\",criterion_left,criterion_right)\n",
        "              if thresholds[i] == thresholds[i - 1]:\n",
        "                  continue\n",
        "              #updating the variables that store the current best split found so far\n",
        "              if criterion < best_criterion:\n",
        "                  best_criterion = criterion\n",
        "                  best_index = index_b\n",
        "                  best_threshold = (thresholds[i] + thresholds[i - 1]) / 2\n",
        "      return best_index, best_threshold\n",
        "\n",
        "  \n",
        "\n",
        "    def buildTree(self, X, y, depth=0):\n",
        "      num_samples_per_class = []#create an empty list\n",
        "      for i in range(self.classes):\n",
        "        count = np.sum(y == i)\n",
        "        num_samples_per_class.append(count)\n",
        "      predicted_class = np.argmax(num_samples_per_class)\n",
        "      node = {'depth': depth, 'n_samples': len(y), 'predicted_class': predicted_class}\n",
        "      # Split recursively until maximum depth is reached or no more splits are possible\n",
        "      if depth < self.max_depth:\n",
        "          index, threshold = self.bestSplit(X, y)\n",
        "          if index is not None:\n",
        "              left_index = X[:, index] < threshold\n",
        "              X_left = X[left_index] \n",
        "              y_left = y[left_index]\n",
        "              X_right = X[~left_index]\n",
        "              y_right = y[~left_index]\n",
        "              if len(y_left) > self.min_samples_leaf and len(y_right) > self.min_samples_leaf:\n",
        "                  node['splitting_feature'] = index\n",
        "                  node['threshold'] = threshold\n",
        "                  node['left'] = self.buildTree(X_left, y_left, depth + 1)\n",
        "                  node['right'] = self.buildTree(X_right, y_right, depth + 1)\n",
        "      return node"
      ],
      "metadata": {
        "id": "cJNaxqb3EZz5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = DecisionTree(max_depth=4, min_samples_split=10, min_samples_leaf=2,criterion=\"gini\")\n",
        "model1.fit(X_train,y_train)\n",
        "\n",
        "y_pred = model1.predict(X_test)\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy Decision tree\",acc*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alcbYj2bHgjX",
        "outputId": "47d2eb13-f02c-42d5-91a8-940366e42944"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Decision tree 61.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest"
      ],
      "metadata": {
        "id": "sLKsXlgwDl4C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RandomForest:\n",
        "    \n",
        "    def __init__(self, input_classifier, num_trees, min_features):\n",
        "        self.input_classifier = input_classifier\n",
        "        self.num_trees = num_trees\n",
        "        self.min_features = min_features\n",
        "        self.trees = []\n",
        "        self.index_features = None\n",
        "        \n",
        "\n",
        "    def fit(self, X, y):\n",
        "\n",
        "        for i in range(self.num_trees):\n",
        "            sample = len(X)\n",
        "            # Sample with replacement\n",
        "            index = np.random.choice(sample, sample, replace=True)\n",
        "            X_sample = X[index]\n",
        "            y_sample = y[index]\n",
        "            # Select a random subset of features\n",
        "            index_features = np.random.choice(X.shape[1], self.min_features, replace=False)\n",
        "            X_sample = X_sample[:, index_features]\n",
        "            tree = self.input_classifier()\n",
        "            tree.fit(X_sample, y_sample)\n",
        "            self.trees.append(tree)\n",
        "\n",
        "    def predict(self, X):\n",
        "        predictions = []\n",
        "        for inputs in X:\n",
        "            trees_predictions = []\n",
        "            for tree in self.trees:\n",
        "                # Make a prediction for each tree\n",
        "                index_features = np.random.choice(X.shape[1], self.min_features, replace=False)\n",
        "                tree_prediction = tree.predict_helper(inputs[self.index_features])\n",
        "                trees_predictions.append(tree_prediction)\n",
        "            # Select the majority vote from all the tree predictions\n",
        "            majority_vote = Counter(trees_predictions).most_common(X.shape[0])[0][0]\n",
        "            predictions.append(majority_vote)\n",
        "        return predictions\n"
      ],
      "metadata": {
        "id": "LFDMAi5ll65l"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = RandomForest(input_classifier=DecisionTree,num_trees=10, min_features=1)\n",
        "model2.fit(X_train, y_train)\n",
        "y_pred = model2.predict(X_test)\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy Random Forest\", acc*100)"
      ],
      "metadata": {
        "id": "ZiFjPK_tl8iA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4b7e390-5183-418a-c58b-4929e4b3416b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Random Forest 61.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "AdaBoost"
      ],
      "metadata": {
        "id": "JTqRtQXh2qrA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AdaBoost:\n",
        "    def __init__(self, weak_learner, num_learners, learning_rate):\n",
        "        self.weak_learner = weak_learner\n",
        "        self.num_learners = num_learners\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # Initialize weights\n",
        "        weights = np.full(len(X), 1/len(X))\n",
        "        self.learners = []\n",
        "        self.weights = []\n",
        "\n",
        "        for i in range(self.num_learners):\n",
        "            # Fit weak learner on weighted samples\n",
        "            learner = self.weak_learner()\n",
        "            learner.fit(X, y, sample_weight=weights)\n",
        "            self.learners.append(learner)\n",
        "\n",
        "            # Compute weighted error and update weights\n",
        "            y_pred = learner.predict(X)\n",
        "            error = np.sum(weights * (y_pred != y))\n",
        "            alpha = self.learning_rate * np.log((1 - error) / error)\n",
        "            weights = weights * np.exp(alpha * (y_pred != y))\n",
        "            weights = weights / np.sum(weights)\n",
        "\n",
        "            # Save weights for prediction\n",
        "            self.weights.append(alpha)\n",
        "\n",
        "            # Stop early if perfect fit achieved\n",
        "            if error == 0:\n",
        "                break\n",
        "    def predict(self, X):\n",
        "        predictions = np.ones(len(X))\n",
        "        for i in range(len(self.learners)):\n",
        "            learner = self.learners[i]\n",
        "            alpha = self.weights[i]\n",
        "            predictions += alpha * np.array(learner.predict(X))\n",
        "        return np.sign(predictions)\n",
        "\n"
      ],
      "metadata": {
        "id": "3a4BxMI7Lhbu"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model4 = AdaBoost(weak_learner = DecisionTree, num_learners = 50, learning_rate = 0.1)\n",
        "model4.fit(X_train,y_train)\n",
        "y_pred_Boosting = model4.predict(y_test)\n",
        "acc_Boosting = accuracy_score(y_test, y_pred_Boosting)\n",
        "print(\"Accuracy Boosting :\", acc_Boosting*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijLJNhxQLkli",
        "outputId": "4bba8176-45df-4da4-976d-0f361195aec9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Boosting : 39.0\n"
          ]
        }
      ]
    }
  ]
}